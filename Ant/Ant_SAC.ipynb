{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking enviroment states and action sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-03 09:04:03.202307: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-03 09:04:03.433076: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-06-03 09:04:03.582241: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-06-03 09:04:04.269783: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/n/.mujoco/mujoco210/bin:/usr/lib/nvidia\n",
      "2024-06-03 09:04:04.269839: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/n/.mujoco/mujoco210/bin:/usr/lib/nvidia\n",
      "2024-06-03 09:04:04.269843: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected port: 33493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-03 09:04:06.252160: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-03 09:04:06.300305: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-06-03 09:04:06.315916: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-06-03 09:04:06.556218: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/n/anaconda3/envs/RL_env/lib/python3.10/site-packages/cv2/../../lib64:/home/n/.mujoco/mujoco210/bin:/usr/lib/nvidia\n",
      "2024-06-03 09:04:06.556245: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/n/anaconda3/envs/RL_env/lib/python3.10/site-packages/cv2/../../lib64:/home/n/.mujoco/mujoco210/bin:/usr/lib/nvidia\n",
      "2024-06-03 09:04:06.556248: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2024-06-03 09:04:07.224076: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-06-03 09:04:07.508521: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-06-03 09:04:07.516852: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "\n",
      "NOTE: Using experimental fast data loading logic. To disable, pass\n",
      "    \"--load_fast=false\" and report issues on GitHub. More details:\n",
      "    https://github.com/tensorflow/tensorboard/issues/4784\n",
      "\n",
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.10.1 at http://localhost:33493/ (Press CTRL+C to quit)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os.path\n",
    "sys.path.append(\"..\")\n",
    "from SAC_Agent import *\n",
    "from ENV_DETAILS import *\n",
    "import os\n",
    "#os.environ[\"LD_LIBRARY_PATH\"] = \"/usr/local/cuda-12.1/lib64:/usr/local/cuda/lib64:/usr/local/cuda-12.1/lib64:/usr/local/cuda/lib64:/usr/local/cuda-12.1/lib64:/usr/local/cuda/lib64\"\n",
    "\n",
    "from RUN_TENSORBOARD import *\n",
    "\n",
    "events_folder = \"./logs_hyper\"\n",
    "main(\"./logs_hyper\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 16726019556273072535\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 22163030016\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 9064093336981160501\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:01:00.0, compute capability: 8.6\"\n",
      "xla_global_id: 416903419\n",
      "]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-03 09:04:10.928491: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-03 09:04:11.004521: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-06-03 09:04:11.076272: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-06-03 09:04:11.081887: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-06-03 09:04:11.232174: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-06-03 09:04:11.234406: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-06-03 09:04:11.235905: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-06-03 09:04:11.237336: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /device:GPU:0 with 21136 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.name == 'nt':\n",
    "    main_hyper_dir = \"D:\\\\Artificial_Intelligence\\\\Portfolio\\\\RL_updated\\\\BipedalWalker\\\\\" # Windows\n",
    "    conda_python_exec = 'C:\\\\Users\\\\yanie\\\\anaconda3\\\\envs\\\\ai_dev\\\\python.exe '# Windows\n",
    "    logs_dir = main_hyper_dir+'Hyperparam_tuning\\\\' # Windows\n",
    "else:\n",
    "    main_hyper_dir = \"/media/n/NewDisk/Artificial_Intelligence/Portfolio/RL_updated/BipedalWalker/\" # Linux\n",
    "    conda_python_exec = '/home/n/anaconda3/envs/ai_dev/bin/python '# Linux\n",
    "    logs_dir = main_hyper_dir+'Hyperparam_tuning_sac/' # Linux\n",
    "\n",
    "ENV = \"Ant-v2\"\n",
    "SUCESS_CRITERIA_VALUE = ENV_DETAILS[ENV][\"SUCESS_CRITERIA_VALUE\"]\n",
    "SUCESS_CRITERIA_EPOCH = ENV_DETAILS[ENV][\"SUCESS_CRITERIA_EPOCH\"]\n",
    "EPISODES = ENV_DETAILS[ENV][\"EPISODES\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TimeLimit<OrderEnforcing<AntEnv<Ant-v2>>>>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "env = gym.make(ENV)\n",
    "env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "max_steps = env._max_episode_steps\n",
    "max_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.53701129, -1.23826046,  1.09599194, -0.20900545, -0.46856472,\n",
       "       -2.07133273, -0.58197674,  0.29742884,  0.05734204,  1.87421852,\n",
       "        1.39635603, -0.04058313,  0.53434915,  0.17526736, -0.29582431,\n",
       "        1.06973615,  1.47717622,  1.21030561,  0.39037437, -1.14250602,\n",
       "        0.74349054,  1.05406054,  0.10168511,  0.61258951, -0.95473605,\n",
       "       -2.37575167,  0.96703566,  0.92393045, -0.27053923, -0.95297787,\n",
       "        0.27663833,  0.5117088 ,  0.02105973,  0.07619108, -0.68034917,\n",
       "        2.27770704,  0.50030299,  0.18707868,  0.94469888, -0.87377495,\n",
       "       -0.01208954,  1.44641464,  1.0181596 , -1.12380213, -0.23147754,\n",
       "       -0.98218457,  0.69291558,  0.76460636, -0.27680122, -0.68987499,\n",
       "       -1.07789889,  0.48176269, -0.39681895,  0.22344762, -0.98309933,\n",
       "       -0.51379566, -2.13782736, -0.18075732,  1.90442008, -0.460754  ,\n",
       "       -0.14285236,  0.11210213,  0.54392848,  0.36741398,  0.28758845,\n",
       "        0.34873197, -0.85929625,  0.8295016 ,  0.93232582,  0.78862661,\n",
       "       -0.01443001, -0.18362985, -0.66827264,  0.64985889, -1.29950881,\n",
       "       -0.01152915,  0.46264714, -2.62358134, -0.03964216, -1.22965392,\n",
       "       -0.00934898,  2.17843131,  0.92010482, -1.29610874,  0.6592062 ,\n",
       "       -0.78682383, -1.02440514,  0.06567576, -0.16192995,  0.21781323,\n",
       "        0.28838441,  0.4407593 ,  0.12766283, -0.62371342,  0.06688025,\n",
       "        0.83443057,  0.50060501, -0.17384863, -0.32878185,  0.30640003,\n",
       "        0.06596974,  0.48834449,  1.04697126,  1.30010865, -1.8204387 ,\n",
       "       -0.13402811,  0.39961018,  0.23653549,  0.87520199, -0.27171363,\n",
       "       -1.04938291])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = env.observation_space.sample()\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box(-inf, inf, (111,), float64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(111,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7068970850993898"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = env.reset()\n",
    "s[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.29599658, -0.10200141, -0.84239125,  0.3846963 , -0.8314808 ,\n",
       "         0.46501842,  0.2606529 ,  0.74407357], dtype=float32),\n",
       " (8,),\n",
       " (1, 8))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = env.action_space.sample()\n",
    "a, a.shape, a.reshape((1, len(a))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.725182  ,  0.99411198,  0.08278237, -0.03350727,  0.06136545,\n",
       "        -0.09525983,  0.44562683, -0.15346137, -0.41174159, -0.04724358,\n",
       "        -0.39104489, -0.13426973,  0.4205014 , -0.37336194,  0.01319626,\n",
       "         0.09834487,  0.26922988, -0.65555473,  1.86323932, -6.05166567,\n",
       "        11.96263119, -6.11104075, -5.94650923,  1.85832676, -5.69567357,\n",
       "        -1.94735672,  8.65204472,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ]),\n",
       " -0.45609440646155863,\n",
       " False,\n",
       " {'reward_forward': -0.21368422350867777,\n",
       "  'reward_ctrl': -1.2424101829528809,\n",
       "  'reward_contact': -0.0,\n",
       "  'reward_survive': 1.0})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.step(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.63243955,  0.683593  , -0.70980513, -0.8365789 , -0.09533732,\n",
       "       -0.40708122, -0.32043636, -0.06856351], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space.sample()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training/Hyperparam run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "TUNING_TYPE = \"BAYES\"\n",
    "HYPERPARAM_TUNING = True\n",
    "writer= \"logs_hyper/fit_sac/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from Hyperparam_kt_sac/keras_tunning_soft/tuner0.json\n"
     ]
    }
   ],
   "source": [
    "if HYPERPARAM_TUNING:\n",
    "\n",
    "    dir = r\"Hyperparam_kt_sac\"\n",
    "    project_name = \"keras_tunning_soft\"\n",
    "\n",
    "    tuner = kt.BayesianOptimization(\n",
    "            MyHyperModel( hyper_dir = dir+\"/\"+project_name,  writer = \"logs_hyper/sac/\",\n",
    "                        end_of_episode = EPISODES, evaluation_epoch = 4000, training_steps = 1000000,\n",
    "                sucess_criteria_epochs = SUCESS_CRITERIA_EPOCH, sucess_criteria_value= SUCESS_CRITERIA_VALUE,        \n",
    "                discount = 0.99,\n",
    "                #discount_min = 0.95, discount_max = 0.99,      \n",
    "                      \n",
    "                #min_lr_actor_critic = 0.00001, max_lr_actor_critic= 0.001,\n",
    "                lr_actor_min = 0.0001, lr_actor_max = 0.001,\n",
    "                lr_critic_1_min = 0.0001, lr_critic_1_max = 0.001, \n",
    "                \n",
    "                #dense_unit=256,\n",
    "                dense_min = 128, dense_max = 400,\n",
    "                \n",
    "                environment_name=ENV,\n",
    "                #tau = 0.005,\n",
    "                tau_min = 0.001, tau_max = 0.1,\n",
    "                \n",
    "                num_layers_act = 2, num_layers_crit =2,\n",
    "                #max_num_layers_act = 2, max_num_layers_crit=2\n",
    "                ),\n",
    "            objective= kt.Objective('total_train_reward', direction=\"max\"), \n",
    "            max_trials = 30,\n",
    "            # distribution_strategy= strategy,\n",
    "            directory=dir,\n",
    "            project_name=project_name,\n",
    "            #seed=0\n",
    "        )\n",
    "    tuner.search(x=[0], y=[1])\n",
    "else : \n",
    "    \n",
    "        print(\"Acquiring parameters ....\")\n",
    "\n",
    "        \n",
    "        run_training(\n",
    "            training_steps = 1500000,  \n",
    "            train_epochs = 50,\n",
    "            evaluation_epoch = 4000,\n",
    "            environment_name = ENV,\n",
    "            end_of_episode= EPISODES,\n",
    "            sucess_criteria_epochs = SUCESS_CRITERIA_EPOCH,\n",
    "            sucess_criteria_value= SUCESS_CRITERIA_VALUE,\n",
    "            discount= 0.99, \n",
    "            dense_units_act = [256,256],  \n",
    "            dense_units_crit = [256,256], \n",
    "            num_layer_a= 2, \n",
    "            num_layer_c= 2, \n",
    "            writer = writer, \n",
    "            reward_scaler = 1, \n",
    "            lr_actor= 0.001,\n",
    "            lr_critic_1= 0.001, \n",
    "            lr_alpha = 0.001, \n",
    "            tau = 0.005,\n",
    "            return_agent = False\n",
    "            )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial id :08 | Score :5103.516037249373 --> {'lr_actor': 0.0006667990304885897, 'lr_critic_1': 0.00048124792129433804, 'lr_alpha': 0.0004797657847307054, 'tau': 0.003816636888154665, 'dense_units_act_0': 367, 'dense_units_act_1': 293, 'dense_units_crit_0': 316, 'dense_units_crit_1': 361}\n",
      "Trial id :24 | Score :4779.580219640848 --> {'lr_actor': 0.0006707435033818824, 'lr_critic_1': 0.00048671928030413953, 'lr_alpha': 0.00046512508629771115, 'tau': 0.0025426492991119246, 'dense_units_act_0': 363, 'dense_units_act_1': 296, 'dense_units_crit_0': 325, 'dense_units_crit_1': 359}\n",
      "Trial id :25 | Score :4625.597881841125 --> {'lr_actor': 0.0005531115987300291, 'lr_critic_1': 0.0003943640979913594, 'lr_alpha': 0.0004457955595309533, 'tau': 0.001, 'dense_units_act_0': 400, 'dense_units_act_1': 291, 'dense_units_crit_0': 287, 'dense_units_crit_1': 400}\n",
      "Trial id :26 | Score :4591.503914590674 --> {'lr_actor': 0.0007836214655753707, 'lr_critic_1': 0.00044518715559338805, 'lr_alpha': 0.0006983590304018242, 'tau': 0.001, 'dense_units_act_0': 400, 'dense_units_act_1': 296, 'dense_units_crit_0': 304, 'dense_units_crit_1': 400}\n",
      "Trial id :28 | Score :4251.404191793674 --> {'lr_actor': 0.0008044690795801494, 'lr_critic_1': 0.00022977817000709313, 'lr_alpha': 0.0004800975936501013, 'tau': 0.0015665419380398876, 'dense_units_act_0': 386, 'dense_units_act_1': 271, 'dense_units_crit_0': 297, 'dense_units_crit_1': 366}\n"
     ]
    }
   ],
   "source": [
    "exploration_tech = \"soft\"\n",
    "hyperparam_combination=[]\n",
    "for trials in tuner.oracle.get_best_trials(num_trials=5):\n",
    "    print(f\"Trial id :{trials.trial_id} | Score :{trials.score} -->\",trials.hyperparameters.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 1244045/1700000 [8:56:14<5:02:23, 25.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1244000 : Reward Train: 2261.301779692914 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 1248012/1700000 [8:58:29<4:37:22, 27.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1248000 : Reward Train: 2037.1344461704562 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▎  | 1252047/1700000 [9:00:48<4:02:19, 30.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1252000 : Reward Train: 1570.268912609368 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 1256044/1700000 [9:03:03<4:44:47, 25.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1256000 : Reward Train: 1342.8231010137924 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 1260045/1700000 [9:05:18<4:42:10, 25.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1260000 : Reward Train: 1263.9433296006762 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 1264047/1700000 [9:07:32<4:28:47, 27.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1264000 : Reward Train: 1015.4850992604363 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 1268046/1700000 [9:09:49<4:34:11, 26.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1268000 : Reward Train: 504.27481287742995 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 1272011/1700000 [9:12:04<4:33:32, 26.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1272000 : Reward Train: 176.43042089585364 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 1276015/1700000 [9:14:23<6:44:20, 17.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1276000 : Reward Train: 2.093328524757276 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 1280041/1700000 [9:16:41<3:27:18, 33.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1280000 : Reward Train: -63.356006344290556 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 1284045/1700000 [9:18:58<4:29:00, 25.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1284000 : Reward Train: -42.09477344734485 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 1288045/1700000 [9:21:15<4:24:10, 25.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1288000 : Reward Train: -52.75334617199685 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 1292045/1700000 [9:23:32<4:31:49, 25.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1292000 : Reward Train: -58.20449649776691 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 1296014/1700000 [9:25:50<6:59:59, 16.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1296000 : Reward Train: -83.29211965914352 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▋  | 1300043/1700000 [9:28:07<4:22:52, 25.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1300000 : Reward Train: -107.98412991741777 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 1304042/1700000 [9:30:25<4:19:36, 25.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1304000 : Reward Train: -113.90837228033037 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 1308018/1700000 [9:32:41<4:20:25, 25.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1308000 : Reward Train: -147.25271160395286 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 1312015/1700000 [9:35:01<6:24:26, 16.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1312000 : Reward Train: -147.72559962814682 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 1316045/1700000 [9:37:18<4:08:31, 25.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1316000 : Reward Train: -173.98707376996802 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 1320047/1700000 [9:39:37<4:09:54, 25.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1320000 : Reward Train: -230.12762517932256 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 1324015/1700000 [9:41:56<6:06:22, 17.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1324000 : Reward Train: -305.21775340536857 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 1328047/1700000 [9:44:15<3:57:56, 26.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1328000 : Reward Train: -461.6766661856447 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 1332017/1700000 [9:46:31<5:44:31, 17.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1332000 : Reward Train: -623.7080787325016 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▊  | 1336017/1700000 [9:48:46<5:52:56, 17.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1336000 : Reward Train: -726.488495497491 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 1340015/1700000 [9:51:04<6:12:43, 16.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1340000 : Reward Train: -728.1612241147485 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 1344047/1700000 [9:53:23<3:45:18, 26.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1344000 : Reward Train: -739.5011585606061 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 1348043/1700000 [9:55:40<3:53:49, 25.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1348000 : Reward Train: -719.3482117879707 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 1352044/1700000 [9:58:02<2:57:41, 32.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1352000 : Reward Train: -642.4818439164427 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 1356043/1700000 [10:00:35<3:05:31, 30.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1356000 : Reward Train: -525.6672239117202 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 1360050/1700000 [10:03:07<2:45:29, 34.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1360000 : Reward Train: -460.9293725168134 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 1364036/1700000 [10:05:38<2:51:20, 32.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1364000 : Reward Train: -387.04005164284166 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 1368043/1700000 [10:08:08<3:40:04, 25.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1368000 : Reward Train: -266.3281697337454 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 1372045/1700000 [10:10:31<2:38:26, 34.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1372000 : Reward Train: -204.632073987946 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 1375997/1700000 [10:12:49<2:34:52, 34.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1376000 : Reward Train: -8.591048707671725 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 1380018/1700000 [10:15:09<3:28:14, 25.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1380000 : Reward Train: 109.30475618056794 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████▏ | 1384017/1700000 [10:17:24<4:52:42, 17.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1384000 : Reward Train: 197.6334544771301 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 1388007/1700000 [10:19:41<5:10:31, 16.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1388000 : Reward Train: 346.78307609576194 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 1392045/1700000 [10:21:59<3:11:20, 26.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1392000 : Reward Train: 481.1983367991655 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 1396041/1700000 [10:24:16<2:46:18, 30.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1396000 : Reward Train: 672.2886266064409 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 1400014/1700000 [10:26:30<4:42:14, 17.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1400000 : Reward Train: 799.5654545642168 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 1404019/1700000 [10:28:45<4:29:28, 18.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1404000 : Reward Train: 970.935421198543 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 1408045/1700000 [10:31:02<3:07:02, 26.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1408000 : Reward Train: 1198.4255128776938 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 1412020/1700000 [10:33:19<4:25:42, 18.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1412000 : Reward Train: 1419.4165096602294 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 1416045/1700000 [10:35:37<2:59:53, 26.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1416000 : Reward Train: 1577.831241608721 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▎ | 1420019/1700000 [10:37:54<4:16:41, 18.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1420000 : Reward Train: 1785.7424589941647 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 1424019/1700000 [10:40:11<4:14:22, 18.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1424000 : Reward Train: 2058.2328133808523 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 1428019/1700000 [10:42:27<3:31:56, 21.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1428000 : Reward Train: 2253.6232153132505 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 1432019/1700000 [10:44:43<4:01:10, 18.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1432000 : Reward Train: 2454.2160917660167 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 1436014/1700000 [10:46:59<4:14:20, 17.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1436000 : Reward Train: 2544.781847157285 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 1440010/1700000 [10:49:16<4:18:44, 16.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1440000 : Reward Train: 2493.7434436124327 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 1444012/1700000 [10:51:33<2:38:23, 26.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1444000 : Reward Train: 2441.1667593836196 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 1448011/1700000 [10:53:48<2:35:08, 27.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1448000 : Reward Train: 2400.423594584772 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 1452048/1700000 [10:56:06<2:37:03, 26.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1452000 : Reward Train: 2343.7934739538973 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 1456015/1700000 [10:58:22<3:52:24, 17.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1456000 : Reward Train: 2191.1311924537404 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 1460016/1700000 [11:00:41<3:58:24, 16.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1460000 : Reward Train: 2018.106482898352 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 1464047/1700000 [11:02:58<2:32:10, 25.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1464000 : Reward Train: 1883.8307733922568 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▋ | 1468020/1700000 [11:05:15<3:45:55, 17.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1468000 : Reward Train: 1844.108741955339 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 1472014/1700000 [11:07:31<2:58:19, 21.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1472000 : Reward Train: 1916.9011545168594 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 1476010/1700000 [11:09:49<3:43:43, 16.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1476000 : Reward Train: 1953.8016080935276 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 1480018/1700000 [11:12:05<3:24:34, 17.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1480000 : Reward Train: 2059.704719938828 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 1484018/1700000 [11:14:22<3:25:16, 17.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1484000 : Reward Train: 2164.415758012876 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 1488007/1700000 [11:16:40<3:37:36, 16.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1488000 : Reward Train: 2256.559740407281 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 1492016/1700000 [11:18:57<3:16:45, 17.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1492000 : Reward Train: 2346.7904318223386 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 1496047/1700000 [11:21:14<2:09:25, 26.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1496000 : Reward Train: 2341.2138221209457 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 1500050/1700000 [11:23:32<2:18:04, 24.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1500000 : Reward Train: 2421.752191715843 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 1504048/1700000 [11:25:49<2:23:01, 22.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1504000 : Reward Train: 2481.746377754655 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▊ | 1508001/1700000 [11:28:06<3:22:42, 15.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1508000 : Reward Train: 2463.798420038321 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 1512019/1700000 [11:30:23<2:50:32, 18.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1512000 : Reward Train: 2527.026391628441 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 1516001/1700000 [11:32:38<3:04:37, 16.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1516000 : Reward Train: 2553.6466539104613 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 1520047/1700000 [11:34:54<1:51:50, 26.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1520000 : Reward Train: 2536.924287446601 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 1524043/1700000 [11:37:08<1:54:22, 25.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1524000 : Reward Train: 2824.8016989106295 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 1528047/1700000 [11:39:23<1:47:20, 26.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1528000 : Reward Train: 3103.100284300776 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 1532046/1700000 [11:41:38<1:45:07, 26.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1532000 : Reward Train: 3345.9083637718063 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 1536048/1700000 [11:43:54<1:40:39, 27.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1536000 : Reward Train: 3596.6576956764584 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 1540048/1700000 [11:46:08<1:38:32, 27.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1540000 : Reward Train: 3858.2043668980277 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 1544047/1700000 [11:48:24<1:37:10, 26.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1544000 : Reward Train: 4097.415238972104 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 1548047/1700000 [11:50:39<1:33:02, 27.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1548000 : Reward Train: 4336.139887091047 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████▏| 1552050/1700000 [11:52:56<1:37:31, 25.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1552000 : Reward Train: 4518.472120633248 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 1556045/1700000 [11:55:12<1:31:58, 26.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1556000 : Reward Train: 4768.435334583292 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 1560048/1700000 [11:57:28<1:27:12, 26.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1560000 : Reward Train: 5031.46484617062 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 1564016/1700000 [11:59:43<2:18:01, 16.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1564000 : Reward Train: 5103.364843410846 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 1568045/1700000 [12:01:58<1:23:29, 26.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1568000 : Reward Train: 5258.810006748839 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 1572044/1700000 [12:04:14<1:20:22, 26.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1572000 : Reward Train: 5335.497456158892 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 1576001/1700000 [12:06:29<2:02:36, 16.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1576000 : Reward Train: 5377.013858581586 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 1580001/1700000 [12:08:44<2:06:23, 15.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1580000 : Reward Train: 5388.621098854196 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 1584017/1700000 [12:10:58<1:46:10, 18.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1584000 : Reward Train: 5401.167214465915 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 1588046/1700000 [12:13:14<1:09:53, 26.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1588000 : Reward Train: 5368.916081509432 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▎| 1592046/1700000 [12:15:29<1:08:44, 26.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1592000 : Reward Train: 5376.185550745814 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 1596017/1700000 [12:17:44<1:34:48, 18.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1596000 : Reward Train: 5402.60512448426 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 1600046/1700000 [12:19:58<46:42, 35.66it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1600000 : Reward Train: 5344.991861830785 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 1604038/1700000 [12:22:13<1:05:04, 24.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1604000 : Reward Train: 5408.760926869709 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 1608017/1700000 [12:24:28<1:23:12, 18.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1608000 : Reward Train: 5409.017127150303 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 1612048/1700000 [12:26:45<53:49, 27.23it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1612000 : Reward Train: 5363.327550746629 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 1616039/1700000 [12:29:00<56:33, 24.74it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1616000 : Reward Train: 5424.009772519997 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 1620047/1700000 [12:31:16<49:33, 26.89it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1620000 : Reward Train: 5421.883923782697 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 1624047/1700000 [12:33:31<48:01, 26.36it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1624000 : Reward Train: 5422.1774662644575 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 1628046/1700000 [12:35:47<44:57, 26.68it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1628000 : Reward Train: 5427.986495636782 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 1632001/1700000 [12:38:03<1:08:34, 16.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1632000 : Reward Train: 5387.528636914621 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 1636019/1700000 [12:40:18<58:23, 18.26it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1636000 : Reward Train: 5392.495273050458 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▋| 1640001/1700000 [12:42:32<39:34, 25.27it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1640000 : Reward Train: 5340.6343910516325 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 1644001/1700000 [12:44:47<57:15, 16.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1644000 : Reward Train: 5345.998949767423 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 1648013/1700000 [12:47:04<49:18, 17.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1648000 : Reward Train: 5505.4466096992965 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 1652050/1700000 [12:49:19<31:15, 25.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1652000 : Reward Train: 5507.337601428065 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 1656018/1700000 [12:51:36<42:00, 17.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1656000 : Reward Train: 5518.689383591462 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 1660015/1700000 [12:53:51<38:50, 17.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1660000 : Reward Train: 5535.027489396802 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 1664016/1700000 [12:56:07<34:37, 17.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1664000 : Reward Train: 5541.708550934334 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 1668019/1700000 [12:58:21<22:26, 23.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1668000 : Reward Train: 5544.757547529157 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 1672018/1700000 [13:00:36<26:43, 17.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1672000 : Reward Train: 5543.530345840351 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▊| 1676016/1700000 [13:02:52<23:22, 17.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1676000 : Reward Train: 5546.733683784929 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 1680019/1700000 [13:05:05<13:54, 23.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1680000 : Reward Train: 5543.795210889487 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 1684018/1700000 [13:07:21<15:02, 17.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1684000 : Reward Train: 5527.330524457193 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 1688047/1700000 [13:09:37<07:33, 26.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1688000 : Reward Train: 5505.2621517932575 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 1692014/1700000 [13:11:50<05:22, 24.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1692000 : Reward Train: 5509.284795094663 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 1696008/1700000 [13:14:07<03:54, 17.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1696000 : Reward Train: 5574.299662568902 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1700000/1700000 [13:16:19<00:00, 35.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 GPUs for rendering. Using device 0.\n",
      "Final mean reward ' soft ': 5776.714804137907\n"
     ]
    }
   ],
   "source": [
    "val_env = gym.make(ENV)\n",
    "dir = r\"Hyperparam_kt_sac\"\n",
    "\n",
    "for best_hps in tuner.get_best_hyperparameters(num_trials=1):\n",
    "    print(f\"Best Hyperparameters: {best_hps.__dict__}\")\n",
    "    env_model = tuner.hypermodel.build(best_hps)  # Build the model with best hyperparameters\n",
    "\n",
    "    env_model = rerun_training(training_steps  = 1700000, \n",
    "                            save_factor = 50000,  \n",
    "                            model_path = './checkpoints/SACagent',\n",
    "                            sucess_criteria_epochs =SUCESS_CRITERIA_EPOCH, \n",
    "                            sucess_criteria_value = SUCESS_CRITERIA_VALUE, \n",
    "                            return_agent = True, \n",
    "                            model = env_model\n",
    "                            )\n",
    "\n",
    "    final_rewards = final_evaluation(env_model, val_env, n_tries=200, exploration=exploration_tech, sucess_criteria_epochs = SUCESS_CRITERIA_EPOCH,  video_name = \"./sac_\"+exploration_tech+\"_video.mp4\")\n",
    "    print(\"Final mean reward '\",exploration_tech,\"':\", np.mean(final_rewards))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_hp = tuner.get_best_hyperparameters()[0]\n",
    "# training_steps = 2000000\n",
    "# discount  = best_hp[\"discount\"]\n",
    "# lr_actor  = best_hp[\"lr_actor\"]\n",
    "# lr_critic_1  = best_hp[\"lr_critic_1\"]\n",
    "# tau  = best_hp[\"tau\"]\n",
    "\n",
    "# end_of_episode = EPISODES\n",
    "# sucess_criteria_epochs = SUCESS_CRITERIA_EPOCH\n",
    "# sucess_criteria_value = SUCESS_CRITERIA_VALUE\n",
    "# save_factor=50000\n",
    "# return_agent = True\n",
    "# reward_scaler = 100\n",
    "# environment_name=ENV\n",
    "\n",
    "# n_dense_layers_actor = trials.hyperparameters.values[\"n_dense_layers_actor\"]\n",
    "# dense_layers_actor = []\n",
    "# for i in range(n_dense_layers_actor):\n",
    "#     dense_layers_actor.append(trials.hyperparameters.values['dense_units_act_'+str(i)])\n",
    "\n",
    "# n_dense_layers_critic = trials.hyperparameters.values[\"n_dense_layers_critic\"]\n",
    "# dense_layers_critic = []\n",
    "# for i in range(n_dense_layers_critic):\n",
    "#     dense_layers_critic.append(trials.hyperparameters.values['dense_units_crit_'+str(i)])\n",
    "\n",
    "# env_model = run_training(training_steps = training_steps,\n",
    "#                          discount = discount,  \n",
    "#                          dense_units_act = dense_layers_actor,  \n",
    "#                          dense_units_crit = dense_layers_critic, \n",
    "#                          num_layer_a = n_dense_layers_actor, \n",
    "#                          num_layer_c = n_dense_layers_critic, \n",
    "#                          writer = writer, \n",
    "#                          end_of_episode = end_of_episode, \n",
    "#                          save_factor = save_factor, \n",
    "#                          sucess_criteria_epochs = sucess_criteria_epochs , \n",
    "#                          sucess_criteria_value = sucess_criteria_value, \n",
    "#                          environment_name = environment_name, \n",
    "#                          reward_scaler = reward_scaler , \n",
    "#                          return_agent = return_agent,\n",
    "#                          lr_actor = lr_actor, \n",
    "#                          lr_critic_1 = lr_critic_1, \n",
    "#                          tau = tau )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_rewards = final_evaluation(env_model,val_env,n_tries=200, exploration=exploration_tech,  video_name = \"./sac_\"+exploration_tech+\"_video.mp4\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "MountainCar_A3C_TF1.ipynb",
   "provenance": [
    {
     "file_id": "13V9JMDwUOkrM9DucPAwwgBQfllmy9kjl",
     "timestamp": 1578567519575
    },
    {
     "file_id": "1rnkjQiF2XrsLm9SMvOuTxe8vX_7hZozI",
     "timestamp": 1578558966437
    }
   ]
  },
  "kernelspec": {
   "display_name": "rl_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "vscode": {
   "interpreter": {
    "hash": "7879325296583a7806f15309d0945146a04fe73b0286fa5dbd4cdc57d601416b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
