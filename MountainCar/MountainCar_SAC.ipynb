{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking enviroment states and action sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-20 08:46:09.441078: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-20 08:46:09.504749: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-11-20 08:46:09.520649: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-20 08:46:09.827621: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/n/anaconda3/envs/RL_env/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2023-11-20 08:46:09.827651: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/n/anaconda3/envs/RL_env/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2023-11-20 08:46:09.827666: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n",
      "Num devices available:  [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-20 08:46:10.672836: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-20 08:46:10.718543: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-20 08:46:10.718724: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os.path\n",
    "sys.path.append(\"..\")\n",
    "from SAC_Agent import *\n",
    "from ENV_DETAILS import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENV = \"MountainCarContinuous-v0\"\n",
    "SUCESS_CRITERIA_VALUE = ENV_DETAILS[ENV][\"SUCESS_CRITERIA_VALUE\"]\n",
    "SUCESS_CRITERIA_EPOCH = ENV_DETAILS[ENV][\"SUCESS_CRITERIA_EPOCH\"]\n",
    "EPISODES = ENV_DETAILS[ENV][\"EPISODES\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TimeLimit<OrderEnforcing<Continuous_MountainCarEnv<MountainCarContinuous-v0>>>>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "env = gym.make(ENV)\n",
    "env\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.6837731 ,  0.00882459], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = env.observation_space.sample()\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Box([-1.2  -0.07], [0.6  0.07], (2,), float32), (2,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space, env.observation_space.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.46692708"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = env.reset()\n",
    "s[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Box(-1.0, 1.0, (1,), float32),\n",
       " Box(-1.0, 1.0, (1,), float32),\n",
       " (array([-0.45186692, -0.00121874], dtype=float32),\n",
       "  -0.02030837898803526,\n",
       "  False,\n",
       "  {}))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = env.reset()\n",
    "env.action_space, env.action_space, env.step(s)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training/Hyperparam run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%tensorboard` not found.\n"
     ]
    }
   ],
   "source": [
    "%tensorboard --logdir logs_general/hyper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "TUNING_TYPE = \"BAYES\"\n",
    "HYPERPARAM_TUNING = True\n",
    "RUN_TRAINING = True\n",
    "writer= \"Training/fit_A3C/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from Hyperparam_kt_sac/keras_tunning_soft/tuner0.json\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error reloading `Oracle` from existing project. If you did not mean to reload from an existing project, change the `project_name` or pass `overwrite=True` when creating the `Tuner`. Found existing project at: Hyperparam_kt_sac/keras_tunning_soft",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/RL_env/lib/python3.9/site-packages/keras_tuner/src/engine/oracle.py:748\u001b[0m, in \u001b[0;36mOracle.reload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    747\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 748\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mreload(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_oracle_fname())\n\u001b[1;32m    749\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/envs/RL_env/lib/python3.9/site-packages/keras_tuner/src/engine/stateful.py:71\u001b[0m, in \u001b[0;36mStateful.reload\u001b[0;34m(self, fname)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Reloads this object using `set_state`.\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \n\u001b[1;32m     68\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[39m    fname: A string, the file name to restore from.\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m---> 71\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mset_state(utils\u001b[39m.\u001b[39;49mload_json(fname))\n",
      "File \u001b[0;32m~/anaconda3/envs/RL_env/lib/python3.9/site-packages/keras_tuner/src/tuners/bayesian.py:224\u001b[0m, in \u001b[0;36mBayesianOptimizationOracle.set_state\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mset_state\u001b[39m(\u001b[39mself\u001b[39m, state):\n\u001b[0;32m--> 224\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mset_state(state)\n\u001b[1;32m    225\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_initial_points \u001b[39m=\u001b[39m state[\u001b[39m\"\u001b[39m\u001b[39mnum_initial_points\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/RL_env/lib/python3.9/site-packages/keras_tuner/src/engine/oracle.py:705\u001b[0m, in \u001b[0;36mOracle.set_state\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mset_state\u001b[39m(\u001b[39mself\u001b[39m, state):\n\u001b[1;32m    704\u001b[0m     \u001b[39m# `self.trials` are saved in their own, Oracle-agnostic files.\u001b[39;00m\n\u001b[0;32m--> 705\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mongoing_trials \u001b[39m=\u001b[39m {\n\u001b[1;32m    706\u001b[0m         tuner_id: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrials[trial_id]\n\u001b[1;32m    707\u001b[0m         \u001b[39mfor\u001b[39;00m tuner_id, trial_id \u001b[39min\u001b[39;00m state[\u001b[39m\"\u001b[39m\u001b[39mongoing_trials\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mitems()\n\u001b[1;32m    708\u001b[0m     }\n\u001b[1;32m    709\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhyperparameters \u001b[39m=\u001b[39m hp_module\u001b[39m.\u001b[39mHyperParameters\u001b[39m.\u001b[39mfrom_config(\n\u001b[1;32m    710\u001b[0m         state[\u001b[39m\"\u001b[39m\u001b[39mhyperparameters\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    711\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/RL_env/lib/python3.9/site-packages/keras_tuner/src/engine/oracle.py:706\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mset_state\u001b[39m(\u001b[39mself\u001b[39m, state):\n\u001b[1;32m    704\u001b[0m     \u001b[39m# `self.trials` are saved in their own, Oracle-agnostic files.\u001b[39;00m\n\u001b[1;32m    705\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mongoing_trials \u001b[39m=\u001b[39m {\n\u001b[0;32m--> 706\u001b[0m         tuner_id: \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrials[trial_id]\n\u001b[1;32m    707\u001b[0m         \u001b[39mfor\u001b[39;00m tuner_id, trial_id \u001b[39min\u001b[39;00m state[\u001b[39m\"\u001b[39m\u001b[39mongoing_trials\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mitems()\n\u001b[1;32m    708\u001b[0m     }\n\u001b[1;32m    709\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhyperparameters \u001b[39m=\u001b[39m hp_module\u001b[39m.\u001b[39mHyperParameters\u001b[39m.\u001b[39mfrom_config(\n\u001b[1;32m    710\u001b[0m         state[\u001b[39m\"\u001b[39m\u001b[39mhyperparameters\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    711\u001b[0m     )\n",
      "\u001b[0;31mKeyError\u001b[0m: '09'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/media/n/New Disk/Artificial_Intelligence/Portfolio/RL_updated/MountainCar/MountainCar_SAC.ipynb Cell 12\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell:/media/n/New%20Disk/Artificial_Intelligence/Portfolio/RL_updated/MountainCar/MountainCar_SAC.ipynb#X14sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39mdir\u001b[39m \u001b[39m=\u001b[39m \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mHyperparam_kt_sac\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/media/n/New%20Disk/Artificial_Intelligence/Portfolio/RL_updated/MountainCar/MountainCar_SAC.ipynb#X14sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     project_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mkeras_tunning_soft\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/media/n/New%20Disk/Artificial_Intelligence/Portfolio/RL_updated/MountainCar/MountainCar_SAC.ipynb#X14sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     tuner \u001b[39m=\u001b[39m kt\u001b[39m.\u001b[39;49mBayesianOptimization(\n\u001b[1;32m      <a href='vscode-notebook-cell:/media/n/New%20Disk/Artificial_Intelligence/Portfolio/RL_updated/MountainCar/MountainCar_SAC.ipynb#X14sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m             MyHyperModel( hyper_dir \u001b[39m=\u001b[39;49m \u001b[39mdir\u001b[39;49m\u001b[39m+\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m/\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m+\u001b[39;49mproject_name,  writer \u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mlogs_hyper/sac/\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/media/n/New%20Disk/Artificial_Intelligence/Portfolio/RL_updated/MountainCar/MountainCar_SAC.ipynb#X14sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m                         end_of_episode \u001b[39m=\u001b[39;49m EPISODES, evaluation_epoch \u001b[39m=\u001b[39;49m env\u001b[39m.\u001b[39;49m_max_episode_steps, training_steps \u001b[39m=\u001b[39;49m \u001b[39m600000\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/media/n/New%20Disk/Artificial_Intelligence/Portfolio/RL_updated/MountainCar/MountainCar_SAC.ipynb#X14sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m                 sucess_criteria_epochs \u001b[39m=\u001b[39;49m SUCESS_CRITERIA_EPOCH, sucess_criteria_value\u001b[39m=\u001b[39;49m SUCESS_CRITERIA_VALUE,\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/n/New%20Disk/Artificial_Intelligence/Portfolio/RL_updated/MountainCar/MountainCar_SAC.ipynb#X14sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m                 discount_min \u001b[39m=\u001b[39;49m \u001b[39m0.98\u001b[39;49m, discount_max \u001b[39m=\u001b[39;49m \u001b[39m0.99\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/n/New%20Disk/Artificial_Intelligence/Portfolio/RL_updated/MountainCar/MountainCar_SAC.ipynb#X14sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m                 lr_actor_min \u001b[39m=\u001b[39;49m \u001b[39m0.000001\u001b[39;49m, lr_actor_max \u001b[39m=\u001b[39;49m \u001b[39m0.001\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/n/New%20Disk/Artificial_Intelligence/Portfolio/RL_updated/MountainCar/MountainCar_SAC.ipynb#X14sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m                 lr_critic_1_min \u001b[39m=\u001b[39;49m \u001b[39m0.000001\u001b[39;49m, lr_critic_1_max \u001b[39m=\u001b[39;49m \u001b[39m0.001\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/n/New%20Disk/Artificial_Intelligence/Portfolio/RL_updated/MountainCar/MountainCar_SAC.ipynb#X14sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m                 dense_min \u001b[39m=\u001b[39;49m \u001b[39m32\u001b[39;49m, dense_max \u001b[39m=\u001b[39;49m \u001b[39m256\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/n/New%20Disk/Artificial_Intelligence/Portfolio/RL_updated/MountainCar/MountainCar_SAC.ipynb#X14sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m                 environment_name\u001b[39m=\u001b[39;49mENV,\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/n/New%20Disk/Artificial_Intelligence/Portfolio/RL_updated/MountainCar/MountainCar_SAC.ipynb#X14sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m                 tau_min \u001b[39m=\u001b[39;49m \u001b[39m0.001\u001b[39;49m, tau_max \u001b[39m=\u001b[39;49m \u001b[39m0.1\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/n/New%20Disk/Artificial_Intelligence/Portfolio/RL_updated/MountainCar/MountainCar_SAC.ipynb#X14sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m                 reward_scaler \u001b[39m=\u001b[39;49m \u001b[39m1\u001b[39;49m, num_layers_act \u001b[39m=\u001b[39;49m \u001b[39m3\u001b[39;49m, num_layers_crit \u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/n/New%20Disk/Artificial_Intelligence/Portfolio/RL_updated/MountainCar/MountainCar_SAC.ipynb#X14sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m                 train_epochs \u001b[39m=\u001b[39;49m \u001b[39m50\u001b[39;49m),\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/n/New%20Disk/Artificial_Intelligence/Portfolio/RL_updated/MountainCar/MountainCar_SAC.ipynb#X14sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m             objective\u001b[39m=\u001b[39;49m kt\u001b[39m.\u001b[39;49mObjective(\u001b[39m'\u001b[39;49m\u001b[39mtotal_train_reward\u001b[39;49m\u001b[39m'\u001b[39;49m, direction\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mmax\u001b[39;49m\u001b[39m\"\u001b[39;49m), \n\u001b[1;32m     <a href='vscode-notebook-cell:/media/n/New%20Disk/Artificial_Intelligence/Portfolio/RL_updated/MountainCar/MountainCar_SAC.ipynb#X14sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m             max_trials \u001b[39m=\u001b[39;49m \u001b[39m30\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/n/New%20Disk/Artificial_Intelligence/Portfolio/RL_updated/MountainCar/MountainCar_SAC.ipynb#X14sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m             directory\u001b[39m=\u001b[39;49m\u001b[39mdir\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/n/New%20Disk/Artificial_Intelligence/Portfolio/RL_updated/MountainCar/MountainCar_SAC.ipynb#X14sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m             project_name\u001b[39m=\u001b[39;49mproject_name\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/n/New%20Disk/Artificial_Intelligence/Portfolio/RL_updated/MountainCar/MountainCar_SAC.ipynb#X14sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m         )\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/n/New%20Disk/Artificial_Intelligence/Portfolio/RL_updated/MountainCar/MountainCar_SAC.ipynb#X14sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     tuner\u001b[39m.\u001b[39msearch(x\u001b[39m=\u001b[39m[\u001b[39m0\u001b[39m], y\u001b[39m=\u001b[39m[\u001b[39m1\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/n/New%20Disk/Artificial_Intelligence/Portfolio/RL_updated/MountainCar/MountainCar_SAC.ipynb#X14sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39melse\u001b[39;00m : \n",
      "File \u001b[0;32m~/anaconda3/envs/RL_env/lib/python3.9/site-packages/keras_tuner/src/tuners/bayesian.py:394\u001b[0m, in \u001b[0;36mBayesianOptimization.__init__\u001b[0;34m(self, hypermodel, objective, max_trials, num_initial_points, alpha, beta, seed, hyperparameters, tune_new_entries, allow_new_entries, max_retries_per_trial, max_consecutive_failed_trials, **kwargs)\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[1;32m    366\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    367\u001b[0m     hypermodel\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    379\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[1;32m    380\u001b[0m ):\n\u001b[1;32m    381\u001b[0m     oracle \u001b[39m=\u001b[39m BayesianOptimizationOracle(\n\u001b[1;32m    382\u001b[0m         objective\u001b[39m=\u001b[39mobjective,\n\u001b[1;32m    383\u001b[0m         max_trials\u001b[39m=\u001b[39mmax_trials,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    392\u001b[0m         max_consecutive_failed_trials\u001b[39m=\u001b[39mmax_consecutive_failed_trials,\n\u001b[1;32m    393\u001b[0m     )\n\u001b[0;32m--> 394\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(oracle\u001b[39m=\u001b[39;49moracle, hypermodel\u001b[39m=\u001b[39;49mhypermodel, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/RL_env/lib/python3.9/site-packages/keras_tuner/src/engine/tuner.py:122\u001b[0m, in \u001b[0;36mTuner.__init__\u001b[0;34m(self, oracle, hypermodel, max_model_size, optimizer, loss, metrics, distribution_strategy, directory, project_name, logger, tuner_id, overwrite, executions_per_trial, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[39mif\u001b[39;00m hypermodel \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39mrun_trial \u001b[39mis\u001b[39;00m Tuner\u001b[39m.\u001b[39mrun_trial:\n\u001b[1;32m    115\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    116\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mReceived `hypermodel=None`. We only allow not specifying \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    117\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`hypermodel` if the user defines the search space in \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    118\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`Tuner.run_trial()` by subclassing a `Tuner` class without \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    119\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39musing a `HyperModel` instance.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    120\u001b[0m     )\n\u001b[0;32m--> 122\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\n\u001b[1;32m    123\u001b[0m     oracle\u001b[39m=\u001b[39;49moracle,\n\u001b[1;32m    124\u001b[0m     hypermodel\u001b[39m=\u001b[39;49mhypermodel,\n\u001b[1;32m    125\u001b[0m     directory\u001b[39m=\u001b[39;49mdirectory,\n\u001b[1;32m    126\u001b[0m     project_name\u001b[39m=\u001b[39;49mproject_name,\n\u001b[1;32m    127\u001b[0m     logger\u001b[39m=\u001b[39;49mlogger,\n\u001b[1;32m    128\u001b[0m     overwrite\u001b[39m=\u001b[39;49moverwrite,\n\u001b[1;32m    129\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    130\u001b[0m )\n\u001b[1;32m    132\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_model_size \u001b[39m=\u001b[39m max_model_size\n\u001b[1;32m    133\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer \u001b[39m=\u001b[39m optimizer\n",
      "File \u001b[0;32m~/anaconda3/envs/RL_env/lib/python3.9/site-packages/keras_tuner/src/engine/base_tuner.py:129\u001b[0m, in \u001b[0;36mBaseTuner.__init__\u001b[0;34m(self, oracle, hypermodel, directory, project_name, overwrite, **kwargs)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m overwrite \u001b[39mand\u001b[39;00m backend\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mexists(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_tuner_fname()):\n\u001b[1;32m    128\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mReloading Tuner from \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_tuner_fname()\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 129\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreload()\n\u001b[1;32m    130\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    131\u001b[0m     \u001b[39m# Only populate initial space if not reloading.\u001b[39;00m\n\u001b[1;32m    132\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_populate_initial_space()\n",
      "File \u001b[0;32m~/anaconda3/envs/RL_env/lib/python3.9/site-packages/keras_tuner/src/engine/base_tuner.py:459\u001b[0m, in \u001b[0;36mBaseTuner.reload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Reloads this object from its project directory.\"\"\"\u001b[39;00m\n\u001b[1;32m    458\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_worker():\n\u001b[0;32m--> 459\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moracle\u001b[39m.\u001b[39;49mreload()\n\u001b[1;32m    460\u001b[0m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mreload(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_tuner_fname())\n",
      "File \u001b[0;32m~/anaconda3/envs/RL_env/lib/python3.9/site-packages/keras_tuner/src/engine/oracle.py:750\u001b[0m, in \u001b[0;36mOracle.reload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    748\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mreload(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_oracle_fname())\n\u001b[1;32m    749\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m--> 750\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    751\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mError reloading `Oracle` from existing project. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    752\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mIf you did not mean to reload from an existing project, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    753\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mchange the `project_name` or pass `overwrite=True` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    754\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mwhen creating the `Tuner`. Found existing \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    755\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mproject at: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_project_dir\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    756\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m    758\u001b[0m \u001b[39m# Empty the ongoing_trials and send them for retry.\u001b[39;00m\n\u001b[1;32m    759\u001b[0m \u001b[39mfor\u001b[39;00m _, trial \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mongoing_trials\u001b[39m.\u001b[39mitems():\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error reloading `Oracle` from existing project. If you did not mean to reload from an existing project, change the `project_name` or pass `overwrite=True` when creating the `Tuner`. Found existing project at: Hyperparam_kt_sac/keras_tunning_soft"
     ]
    }
   ],
   "source": [
    "if HYPERPARAM_TUNING:\n",
    "\n",
    "    dir = r\"Hyperparam_kt_sac\"\n",
    "    project_name = \"keras_tunning_soft\"\n",
    "\n",
    "    tuner = kt.BayesianOptimization(\n",
    "            MyHyperModel( hyper_dir = dir+\"/\"+project_name,  writer = \"logs_hyper/sac/\",\n",
    "                        end_of_episode = EPISODES, evaluation_epoch = env._max_episode_steps, training_steps = 600000,\n",
    "                sucess_criteria_epochs = SUCESS_CRITERIA_EPOCH, sucess_criteria_value= SUCESS_CRITERIA_VALUE,\n",
    "                discount_min = 0.98, discount_max = 0.99,\n",
    "                lr_actor_min = 0.000001, lr_actor_max = 0.001,\n",
    "                lr_critic_1_min = 0.000001, lr_critic_1_max = 0.001,\n",
    "                dense_min = 32, dense_max = 256,\n",
    "                environment_name=ENV,\n",
    "                tau_min = 0.001, tau_max = 0.1,\n",
    "                reward_scaler = 1, num_layers_act = 3, num_layers_crit =3,\n",
    "                train_epochs = 50),\n",
    "            objective= kt.Objective('total_train_reward', direction=\"max\"), \n",
    "            max_trials = 30,\n",
    "            directory=dir,\n",
    "            project_name=project_name\n",
    "        )\n",
    "    tuner.search(x=[0], y=[1])\n",
    "else : \n",
    "        \n",
    "        writer= \"Training/fit_PPO/\"\n",
    "\n",
    "        training_steps = 1000000\n",
    "        lr_actor= 0.0001\n",
    "        lr_critic_1= 0.0001\n",
    "        lr_alpha= 0.0001\n",
    "        entropy_factor = 0.1\n",
    "        discount = 0.99\n",
    "        dense_layers_actor = [128,64]\n",
    "        num_layers_actor = 2\n",
    "        dense_units_critic = [128,64]\n",
    "        num_layers_crit = 2\n",
    "        tau = 0.01\n",
    "        save_factor=50000\n",
    "        reward_scaler = 1\n",
    "        model_path = './checkpoints/SACagent'\n",
    "\n",
    "        if RUN_TRAINING:\n",
    "\n",
    "            print(\"Acquiring parameters ....\")\n",
    "\n",
    "            model = run_training(training_steps = training_steps,\n",
    "                                discount = discount,  \n",
    "                                dense_units_act = dense_layers_actor,  \n",
    "                                dense_units_crit = dense_units_critic, \n",
    "                                num_layer_a = num_layers_actor, \n",
    "                                num_layer_c = num_layers_crit, \n",
    "                                writer = writer, \n",
    "                                end_of_episode = EPISODES, \n",
    "                                save_factor = save_factor, \n",
    "                                sucess_criteria_epochs = SUCESS_CRITERIA_EPOCH , \n",
    "                                sucess_criteria_value = SUCESS_CRITERIA_VALUE, \n",
    "                                environment_name = ENV, \n",
    "                                reward_scaler = 1 , \n",
    "                                evaluation_epoch = env._max_episode_steps, \n",
    "                                return_agent = True,\n",
    "                                lr_actor = lr_actor, \n",
    "                                lr_critic_1 = lr_critic_1, \n",
    "                                lr_alpha = lr_alpha,\n",
    "                                tau = tau,\n",
    "                                train_epochs = 50,\n",
    "                                model_path = model_path\n",
    "                                )\n",
    "        else:\n",
    "        \n",
    "            model = SAC(\n",
    "                discount = discount, \n",
    "                dense_units_act = dense_layers_actor,\n",
    "                dense_units_crit= dense_units_critic, \n",
    "                num_layer_act  = num_layers_actor, \n",
    "                num_layer_crit= num_layers_crit,\n",
    "                writer = writer,\n",
    "                trial_n = get_valid_trials_number(writer),\n",
    "                end_of_episode = EPISODES,\n",
    "                evaluation_epoch = env._max_episode_steps,\n",
    "                environment_name = ENV,\n",
    "                reward_scaler = reward_scaler,\n",
    "                lr_actor = lr_actor, lr_critic = lr_critic_1, lr_alpha= lr_alpha, \n",
    "                tau= tau,\n",
    "                train_epochs = 50\n",
    "            )\n",
    "            model.load_weights(model_path)\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exploration_tech = \"soft_sac\"\n",
    "val_env = gym.make(ENV, render_mode = \"rgb_array\")\n",
    "dir = r\"Hyperparam_kt_sac\"\n",
    "\n",
    "model = tuner.get_best_models()[0]\n",
    "final_rewards = final_evaluation(model,val_env,n_tries=200, exploration=exploration_tech,  video_name = \"./sac_\"+exploration_tech+\"_video.mp4\")\n",
    "print(\"Final mean reward '\",exploration_tech,\"':\", np.mean(final_rewards))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "MountainCar_A3C_TF1.ipynb",
   "provenance": [
    {
     "file_id": "13V9JMDwUOkrM9DucPAwwgBQfllmy9kjl",
     "timestamp": 1578567519575
    },
    {
     "file_id": "1rnkjQiF2XrsLm9SMvOuTxe8vX_7hZozI",
     "timestamp": 1578558966437
    }
   ]
  },
  "kernelspec": {
   "display_name": "rl_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "vscode": {
   "interpreter": {
    "hash": "7879325296583a7806f15309d0945146a04fe73b0286fa5dbd4cdc57d601416b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
