{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking enviroment states and action sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-14 13:15:12.081689: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num devices available:  [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from SARSA_Agent import *\n",
    "from ENV_DETAILS import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.name == 'nt':\n",
    "    main_hyper_dir = \"D:\\\\Artificial_Intelligence\\\\Portfolio\\\\RL_updated\\\\MountainCar\\\\\" # Windows\n",
    "    conda_python_exec = 'C:\\\\Users\\\\yanie\\\\anaconda3\\\\envs\\\\ai_dev\\\\python.exe '# Windows\n",
    "    logs_dir = main_hyper_dir+'Hyperparam_tuning\\\\' # Windows\n",
    "else:\n",
    "    main_hyper_dir = \"/media/n/NewDisk/Artificial_Intelligence/Portfolio/RL_updated/MountainCar/\" # Linux\n",
    "    conda_python_exec = '/home/n/anaconda3/envs/ai_dev/bin/python '# Linux\n",
    "    logs_dir = main_hyper_dir+'Hyperparam_tuning_sarsa/' # Linux\n",
    "    \n",
    "ENV = \"MountainCar-v0\"\n",
    "SUCESS_CRITERIA_VALUE = ENV_DETAILS[ENV][\"SUCESS_CRITERIA_VALUE\"]\n",
    "SUCESS_CRITERIA_EPOCH = ENV_DETAILS[ENV][\"SUCESS_CRITERIA_EPOCH\"]\n",
    "EPISODES = ENV_DETAILS[ENV][\"EPISODES\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TimeLimit<OrderEnforcing<PassiveEnvChecker<MountainCarEnv<MountainCar-v0>>>>>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = gym.make(ENV)#,new_step_api=True\n",
    "env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.32481113, -0.02147825], dtype=float32), (2,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = env.observation_space.sample()\n",
    "s, s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Box([-1.2  -0.07], [0.6  0.07], (2,), float32), (2,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space, env.observation_space.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,\n",
       " Discrete(3),\n",
       " (array([-0.44685495, -0.0005747 ], dtype=float32), -1.0, False, False, {}))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = env.reset()\n",
    "env.action_space.n, env.action_space, env.step(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training/Hyperparam run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%tensorboard` not found.\n"
     ]
    }
   ],
   "source": [
    "%tensorboard --logdir logs_general/hyper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TUNING_TYPE = \"BAYES\"\n",
    "HYPERPARAM_TUNING = True\n",
    "writer= \"Training/fit_SARSA/\"\n",
    "EPISODES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 58 Complete [01h 02m 51s]\n",
      "total_train_reward: -1000.0\n",
      "\n",
      "Best total_train_reward So Far: -909.44\n",
      "Total elapsed time: 1d 04h 14m 35s\n",
      "\n",
      "Search: Running Trial #59\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "0.95              |0.95              |discount\n",
      "0.00059998        |0.00024311        |learning_rate\n",
      "700               |200               |time_to_update\n",
      "62                |491               |dense_units\n",
      "\n",
      "Trial number :  59\n",
      "Epoch: 2000 : Reward eval/Train: -200.0/-1000.0 | epsilon : 1| boltzman : 0.9702989999999999\n",
      "Epoch: 4000 : Reward eval/Train: -200.0/-1000.0 | epsilon : 1| boltzman : 0.9414801494009999\n",
      "Epoch: 6000 : Reward eval/Train: -200.0/-1000.0 | epsilon : 1| boltzman : 0.9135172474836407\n",
      "Epoch: 8000 : Reward eval/Train: -200.0/-1000.0 | epsilon : 1| boltzman : 0.8863848717161291\n",
      "Epoch: 10000 : Reward eval/Train: -200.0/-1000.0 | epsilon : 1| boltzman : 0.8600583546412883\n",
      "Epoch: 12000 : Reward eval/Train: -200.0/-1000.0 | epsilon : 1| boltzman : 0.8345137614500874\n",
      "Epoch: 14000 : Reward eval/Train: -200.0/-1000.0 | epsilon : 1| boltzman : 0.8097278682212583\n",
      "Epoch: 16000 : Reward eval/Train: -200.0/-1000.0 | epsilon : 1| boltzman : 0.7936142836436553\n",
      "Epoch: 18000 : Reward eval/Train: -200.0/-1000.0 | epsilon : 1| boltzman : 0.7700431458051551\n",
      "Epoch: 20000 : Reward eval/Train: -200.0/-1000.0 | epsilon : 1| boltzman : 0.7471720943315961\n",
      "Epoch: 22000 : Reward eval/Train: -200.0/-1000.0 | epsilon : 1| boltzman : 0.7249803359578534\n",
      "Epoch: 24000 : Reward eval/Train: -200.0/-1000.0 | epsilon : 1| boltzman : 0.7034476949995692\n",
      "Epoch: 26000 : Reward eval/Train: -200.0/-1000.0 | epsilon : 1| boltzman : 0.682554595010387\n",
      "Epoch: 28000 : Reward eval/Train: -200.0/-1000.0 | epsilon : 1| boltzman : 0.6622820409839835\n",
      "Epoch: 30000 : Reward eval/Train: -200.0/-1000.0 | epsilon : 1| boltzman : 0.6491026283684022\n",
      "Epoch: 32000 : Reward eval/Train: -200.0/-1000.0 | epsilon : 1| boltzman : 0.6298236312032323\n",
      "Epoch: 34000 : Reward eval/Train: -200.0/-1000.0 | epsilon : 1| boltzman : 0.6111172395328651\n",
      "Epoch: 36000 : Reward eval/Train: -200.0/-1000.0 | epsilon : 1| boltzman : 0.5929664464014994\n",
      "Epoch: 38000 : Reward eval/Train: -200.0/-1000.0 | epsilon : 1| boltzman : 0.5753547499769285\n",
      "Epoch: 40000 : Reward eval/Train: -200.0/-1000.0 | epsilon : 1| boltzman : 0.5582661385478638\n",
      "Epoch: 42000 : Reward eval/Train: -200.0/-1000.0 | epsilon : 1| boltzman : 0.5416850759668536\n",
      "Epoch: 44000 : Reward eval/Train: -200.0/-1000.0 | epsilon : 1| boltzman : 0.5309055429551132\n",
      "Epoch: 46000 : Reward eval/Train: -200.0/-1000.0 | epsilon : 1| boltzman : 0.5151371174238033\n",
      "Epoch: 48000 : Reward eval/Train: -200.0/-1000.0 | epsilon : 1| boltzman : 0.4998370298991989\n",
      "Epoch: 50000 : Reward eval/Train: -200.0/-1000.0 | epsilon : 1| boltzman : 0.48499137027416284\n",
      "Epoch: 52000 : Reward eval/Train: -200.0/-1000.0 | epsilon : 1| boltzman : 0.47058664158564995\n",
      "Epoch: 54000 : Reward eval/Train: -200.0/-1000.0 | epsilon : 1| boltzman : 0.45660974774391455\n",
      "Epoch: 56000 : Reward eval/Train: -200.0/-1000.0 | epsilon : 1| boltzman : 0.44304798162617254\n",
      "Epoch: 58000 : Reward eval/Train: -200.0/-1000.0 | epsilon : 1| boltzman : 0.4342313267918117\n",
      "Epoch: 60000 : Reward eval/Train: -200.0/-1000.0 | epsilon : 1| boltzman : 0.4213342221547681\n",
      "Epoch: 62000 : Reward eval/Train: -200.0/-1000.0 | epsilon : 1| boltzman : 0.40882017442254937\n",
      "Epoch: 64000 : Reward eval/Train: -200.0/-1000.0 | epsilon : 1| boltzman : 0.39667780642202527\n",
      "Epoch: 66000 : Reward eval/Train: -200.0/-1000.0 | epsilon : 1| boltzman : 0.3848960788934847\n",
      "Epoch: 68000 : Reward eval/Train: -200.0/-1000.0 | epsilon : 1| boltzman : 0.37346428045426927\n",
      "Epoch: 70000 : Reward eval/Train: -200.0/-1000.0 | epsilon : 1| boltzman : 0.36237201786049694\n",
      "Epoch: 72000 : Reward eval/Train: -200.0/-1000.0 | epsilon : 1| boltzman : 0.35516081470507305\n",
      "Epoch: 74000 : Reward eval/Train: -200.0/-1000.0 | epsilon : 1| boltzman : 0.34461218334751764\n",
      "Epoch: 76000 : Reward eval/Train: -200.0/-1000.0 | epsilon : 1| boltzman : 0.334376856889913\n",
      "Epoch: 78000 : Reward eval/Train: -200.0/-1000.0 | epsilon : 1| boltzman : 0.3244455298634257\n",
      "Epoch: 80000 : Reward eval/Train: -200.0/-1000.0 | epsilon : 1| boltzman : 0.31480917318095203\n",
      "Epoch: 82000 : Reward eval/Train: -200.0/-1000.0 | epsilon : 1| boltzman : 0.30545902592830454\n",
      "Epoch: 84000 : Reward eval/Train: -200.0/-1000.0 | epsilon : 1| boltzman : 0.2963865873992079\n",
      "Epoch: 86000 : Reward eval/Train: -200.0/-1000.0 | epsilon : 1| boltzman : 0.2904884943099637\n",
      "Epoch: 88000 : Reward eval/Train: -200.0/-1000.0 | epsilon : 1| boltzman : 0.28186069554046345\n",
      "Epoch: 90000 : Reward eval/Train: -200.0/-1000.0 | epsilon : 1| boltzman : 0.27348915102221616\n",
      "Epoch: 92000 : Reward eval/Train: -200.0/-1000.0 | epsilon : 1| boltzman : 0.2653662497477053\n",
      "Epoch: 94000 : Reward eval/Train: -200.0/-1000.0 | epsilon : 1| boltzman : 0.2574846067639487\n",
      "Epoch: 96000 : Reward eval/Train: -200.0/-1000.0 | epsilon : 1| boltzman : 0.24983705645845267\n",
      "Epoch: 98000 : Reward eval/Train: -200.0/-1000.0 | epsilon : 1| boltzman : 0.24241664604458016\n",
      "Epoch: 100000 : Reward eval/Train: -200.0/-1000.0 | epsilon : 1| boltzman : 0.23759255478829303\n",
      "Epoch: 102000 : Reward eval/Train: -200.0/-1000.0 | epsilon : 1| boltzman : 0.23053581831852593\n",
      "Epoch: 104000 : Reward eval/Train: -200.0/-1000.0 | epsilon : 1| boltzman : 0.22368867397864742\n",
      "Epoch: 106000 : Reward eval/Train: -200.0/-1000.0 | epsilon : 1| boltzman : 0.2170448966728076\n",
      "Epoch: 108000 : Reward eval/Train: -200.0/-1000.0 | epsilon : 1| boltzman : 0.21059844619672854\n",
      "Epoch: 110000 : Reward eval/Train: -200.0/-1000.0 | epsilon : 1| boltzman : 0.20434346174623952\n",
      "Epoch: 112000 : Reward eval/Train: -200.0/-1000.0 | epsilon : 1| boltzman : 0.19827425658891445\n",
      "Epoch: 114000 : Reward eval/Train: -200.0/-1000.0 | epsilon : 1| boltzman : 0.19432859888279505\n",
      "Epoch: 116000 : Reward eval/Train: -200.0/-1000.0 | epsilon : 1| boltzman : 0.18855684516737714\n",
      "Epoch: 118000 : Reward eval/Train: -200.0/-1000.0 | epsilon : 1| boltzman : 0.18295651830906087\n",
      "Epoch: 120000 : Reward eval/Train: -200.0/-1000.0 | epsilon : 1| boltzman : 0.17752252675876345\n",
      "Epoch: 122000 : Reward eval/Train: -200.0/-1000.0 | epsilon : 1| boltzman : 0.17224993019150142\n",
      "Epoch: 124000 : Reward eval/Train: -200.0/-1000.0 | epsilon : 1| boltzman : 0.16713393501488363\n"
     ]
    }
   ],
   "source": [
    "if HYPERPARAM_TUNING:\n",
    "\n",
    "    dir = r\"Hyperparam_kt_SARSA\"\n",
    "    project_name = \"keras_tunning_boltzman\"\n",
    "    tuner = kt.BayesianOptimization(\n",
    "            MyHyperModel( hyper_dir = dir+\"/\"+project_name,  writer = \"logs_hyper/SARSA_boltzman/\", exploration_tech ='boltzman' ,\n",
    "                         sucess_criteria_epochs = SUCESS_CRITERIA_EPOCH, sucess_criteria_value = SUCESS_CRITERIA_VALUE,\n",
    "                  end_of_episode = EPISODES, batch = 32,  evaluation_epoch = 2000, \n",
    "                   training_steps = 1000000, \n",
    "                   time_to_update_min = 100, time_to_update_max = 1000,\n",
    "                   lr_min = 0.000005, lr_max = 0.005,\n",
    "                   discount_min = 0.80, discount_max = 0.99,\n",
    "                   dense_min = 32, dense_max = 512,\n",
    "                   environment_name = ENV ),\n",
    "            objective= kt.Objective('total_train_reward', direction=\"max\"), \n",
    "            max_trials = 80,\n",
    "            # distribution_strategy=tf.distribute.MirroredStrategy(),\n",
    "            directory= dir,\n",
    "            project_name=project_name\n",
    "        )\n",
    "    tuner.search(x=[0], y=[1])\n",
    "\n",
    "else : \n",
    "    print(\"Acquiring parameters ....\")\n",
    "    # run_training(training_steps, learning_rate, tau_update_network, exploration_tech, discount, time_to_update, dense_units, writer, end_of_episode)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial id :29 | Score :-749.53 --> {'discount': 0.91, 'learning_rate': 0.0001523256796335738, 'time_to_update': 100, 'dense_units': 459}\n",
      "Trial id :14 | Score :-979.32 --> {'discount': 0.91, 'learning_rate': 0.00014430714988638777, 'time_to_update': 100, 'dense_units': 463}\n",
      "Trial id :16 | Score :-1000.0 --> {'discount': 0.93, 'learning_rate': 0.0035458040975527216, 'time_to_update': 800, 'dense_units': 435}\n"
     ]
    }
   ],
   "source": [
    "exploration_tech=\"boltzman\"\n",
    "\n",
    "hyperparam_combination =[]\n",
    "for trials in tuner.oracle.get_best_trials(num_trials=3):\n",
    "    print(f\"Trial id :{trials.trial_id} | Score :{trials.score} -->\",trials.hyperparameters.values)\n",
    "\n",
    "    disc = trials.hyperparameters.values[\"discount\"]\n",
    "    end_ep = 1000\n",
    "    train_steps = 5000000\n",
    "    d = trials.hyperparameters.values[\"dense_units\"]\n",
    "    lr = trials.hyperparameters.values[\"learning_rate\"]\n",
    "    time_to_update = trials.hyperparameters.values[\"time_to_update\"]\n",
    "\n",
    "    # hyperparam_combination.append((disc, end_ep, lr, tau_update_network, exploration_tech, train_steps, d, time_to_update))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, [])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hyperparam_combination), hyperparam_combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_hyperparam(total_files_number = 4, TUNING_TYPE= \"MANUAL\",  TUNING_TYPE = TUNING_TYPE, hyperparam_combination = hyperparam_combination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Tuner from Hyperparam_kt_SARSA/keras_tunning_epsilon/tuner0.json\n",
      "Trial id :01 | Score :-994.66 --> {'discount': 0.9, 'learning_rate': 2.132075196635335e-05, 'time_to_update': 200, 'dense_units': 54}\n",
      "Trial number :  60\n",
      "Moviepy - Building video ./SARSA_epsilon_video.mp4.\n",
      "Moviepy - Writing video ./SARSA_epsilon_video.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready ./SARSA_epsilon_video.mp4\n",
      "Final mean reward ' epsilon ': -200.0\n",
      "INFO:tensorflow:Reloading Tuner from Hyperparam_kt_SARSA/keras_tunning_boltzman/tuner0.json\n",
      "Trial id :29 | Score :-749.53 --> {'discount': 0.91, 'learning_rate': 0.0001523256796335738, 'time_to_update': 100, 'dense_units': 459}\n",
      "Trial number :  60\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n",
      "Moviepy - Building video ./SARSA_boltzman_video.mp4.\n",
      "Moviepy - Writing video ./SARSA_boltzman_video.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready ./SARSA_boltzman_video.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final mean reward ' boltzman ': -200.0\n"
     ]
    }
   ],
   "source": [
    "val_env = gym.make(ENV , render_mode = \"rgb_array\")\n",
    "dir = r\"Hyperparam_kt_SARSA\"\n",
    "\n",
    "for exploration_tech in [\"epsilon\", \"boltzman\"]:\n",
    "\n",
    "    project_name = \"keras_tunning_\"+exploration_tech\n",
    "    tuner = kt.BayesianOptimization(\n",
    "            MyHyperModel( hyper_dir = dir+\"/\"+project_name,  writer = \"logs_hyper/SARSA_\"+exploration_tech+\"/\", exploration_tech =exploration_tech,\n",
    "                         sucess_criteria_epochs = SUCESS_CRITERIA_EPOCH, sucess_criteria_value = SUCESS_CRITERIA_VALUE,\n",
    "                  end_of_episode = EPISODES, batch = 32,  evaluation_epoch = 2000, \n",
    "                   training_steps = 1000000, \n",
    "                   time_to_update_min = 100, time_to_update_max = 1000,\n",
    "                   lr_min = 0.000005, lr_max = 0.005,\n",
    "                   discount_min = 0.80, discount_max = 0.99,\n",
    "                   dense_min = 32, dense_max = 512,\n",
    "                   environment_name = ENV ),\n",
    "            objective= kt.Objective('total_train_reward', direction=\"max\"), \n",
    "            max_trials = 60,\n",
    "            # distribution_strategy=tf.distribute.MirroredStrategy(),\n",
    "            directory= dir,\n",
    "            project_name=project_name\n",
    "        )\n",
    "\n",
    "    for trials in tuner.oracle.get_best_trials(num_trials=1):\n",
    "        print(f\"Trial id :{trials.trial_id} | Score :{trials.score} -->\",trials.hyperparameters.values)\n",
    "        \n",
    "\n",
    "    env_model = tuner.get_best_models()[0]\n",
    "    final_rewards = final_evaluation(env_model,val_env,n_tries=200, exploration=exploration_tech,  video_name = \"./SARSA_\"+exploration_tech+\"_video.mp4\")\n",
    "    print(\"Final mean reward '\",exploration_tech,\"':\", np.mean(final_rewards))\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "MountainCar_A3C_TF1.ipynb",
   "provenance": [
    {
     "file_id": "13V9JMDwUOkrM9DucPAwwgBQfllmy9kjl",
     "timestamp": 1578567519575
    },
    {
     "file_id": "1rnkjQiF2XrsLm9SMvOuTxe8vX_7hZozI",
     "timestamp": 1578558966437
    }
   ]
  },
  "kernelspec": {
   "display_name": "rl_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "7879325296583a7806f15309d0945146a04fe73b0286fa5dbd4cdc57d601416b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
